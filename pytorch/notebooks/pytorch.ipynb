{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/admin/.pyenv/versions/3.12.5/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/admin/.pyenv/versions/3.12.5/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/admin/.pyenv/versions/3.12.5/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/pp/3zwp4_s56jb51k20dlwb3v8h0000gn/T/ipykernel_4241/4089678309.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/admin/Library/Caches/pypoetry/virtualenvs/generative-ai-zqkb-BGY-py3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Scalar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar: torch.Tensor = torch.tensor(data=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar tensor: 8\n",
      "Number of dimensions: 0 (0D tensor)\n",
      "Shape: torch.Size([]) (No dimensions for a scalar)\n",
      "Scalar value: 8 (Extracted value)\n",
      "Element size: 8 bytes (size of one element)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Scalar tensor: {scalar}\")\n",
    "print(f\"Number of dimensions: {scalar.ndim} (0D tensor)\")\n",
    "print(f\"Shape: {scalar.shape} (No dimensions for a scalar)\")\n",
    "print(f\"Scalar value: {scalar.item()} (Extracted value)\")\n",
    "print(f\"Element size: {scalar.element_size()} bytes (size of one element)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector: torch.Tensor = torch.tensor(data=[8, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector tensor: tensor([8, 5])\n",
      "Number of dimensions: 1 (1D tensor)\n",
      "Shape: torch.Size([2]) (Number of elements)\n",
      "Element size: 8 bytes (size of one element)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vector tensor: {vector}\")\n",
    "print(f\"Number of dimensions: {vector.ndim} (1D tensor)\")\n",
    "print(f\"Shape: {vector.shape} (Number of elements)\")\n",
    "print(f\"Element size: {vector.element_size()} bytes (size of one element)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix: torch.Tensor = torch.tensor(data=[[1, 2], [3, 4], [4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix tensor:\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n",
      "Number of dimensions: 2 (2D tensor)\n",
      "Shape: torch.Size([3, 2]) (Rows, Columns)\n",
      "Element size: 8 bytes (size of one element)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Matrix tensor:\\n{matrix}\")\n",
    "print(f\"Number of dimensions: {matrix.ndim} (2D tensor)\")\n",
    "print(f\"Shape: {matrix.shape} (Rows, Columns)\")\n",
    "print(f\"Element size: {matrix.element_size()} bytes (size of one element)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor: torch.Tensor = torch.tensor(data=[[[1, 2, 3, 4], [3, 2, 1, 0], [4, 5, 6, 5]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[[1, 2, 3, 4],\n",
      "         [3, 2, 1, 0],\n",
      "         [4, 5, 6, 5]]])\n",
      "Number of dimensions: 3 (Tensor rank)\n",
      "Shape: torch.Size([1, 3, 4]) (Dimensions of the tensor)\n",
      "Element size: 8 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tensor:\\n{tensor}\")\n",
    "print(f\"Number of dimensions: {tensor.ndim} (Tensor rank)\")\n",
    "print(f\"Shape: {tensor.shape} (Dimensions of the tensor)\")\n",
    "print(f\"Element size: {tensor.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Random Tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor:\n",
      "tensor([[0.7817, 0.8426, 0.7833, 0.5532],\n",
      "        [0.8951, 0.9909, 0.3634, 0.7415],\n",
      "        [0.2377, 0.4491, 0.4820, 0.5880]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor: torch.Tensor = torch.rand(size=(3, 4))\n",
    "print(f\"Random tensor:\\n{random_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Zeros and Ones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros tensor:\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "zeros: torch.Tensor = torch.zeros(size=(3, 4))\n",
    "print(f\"Zeros tensor:\\n{zeros}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones tensor:\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "ones: torch.Tensor = torch.ones(size=(3, 4))\n",
    "print(f\"Ones tensor:\\n{ones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Arange and Tensor Like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "x: torch.Tensor = torch.arange(start=0, end=10, step=1)\n",
    "print(x)\n",
    "y: torch.Tensor = torch.arange(start=0, end=10, step=2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tensor:\n",
      "tensor([[0.3092, 0.8780],\n",
      "        [0.8937, 0.0450],\n",
      "        [0.2632, 0.5114],\n",
      "        [0.3763, 0.2236]])\n",
      "Number of dimensions: 2 (Tensor rank)\n",
      "Shape: torch.Size([4, 2]) (Dimensions of the tensor)\n",
      "Element size: 4 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "sample: torch.Tensor = torch.rand(size=(4, 2))\n",
    "print(f\"Sample tensor:\\n{sample}\")\n",
    "print(f\"Number of dimensions: {sample.ndim} (Tensor rank)\")\n",
    "print(f\"Shape: {sample.shape} (Dimensions of the tensor)\")\n",
    "print(f\"Element size: {sample.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros tensor:\n",
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "Diension: 2\n",
      "Shape: torch.Size([4, 2]) (Dimensions of the tensor)\n",
      "Element size: 4 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "zeros_like: torch.Tensor = torch.zeros_like(input=sample)\n",
    "print(f\"Zeros tensor:\\n{zeros_like}\")\n",
    "print(f\"Diension: {zeros_like.ndim}\")\n",
    "print(f\"Shape: {zeros_like.shape} (Dimensions of the tensor)\")\n",
    "print(f\"Element size: {zeros_like.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones tensor:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "Diension: 2\n",
      "Shape: torch.Size([4, 2]) (Dimensions of the tensor)\n",
      "Element size: 4 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "ones_like: torch.Tensor = torch.ones_like(input=sample)\n",
    "print(f\"Ones tensor:\\n{ones_like}\")\n",
    "print(f\"Diension: {ones_like.ndim}\")\n",
    "print(f\"Shape: {ones_like.shape} (Dimensions of the tensor)\")\n",
    "print(f\"Element size: {ones_like.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Eye Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eye Tensor:\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "Diension: 2\n",
      "Shape: torch.Size([5, 5]) (Dimensions of the tensor)\n",
      "Element size: 4 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "eye_tensor: torch.Tensor = torch.eye(n=5)\n",
    "print(f\"Eye Tensor:\\n{eye_tensor}\")\n",
    "print(f\"Diension: {ones_like.ndim}\")\n",
    "print(f\"Shape: {eye_tensor.shape} (Dimensions of the tensor)\")\n",
    "print(f\"Element size: {eye_tensor.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Full Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full tensor:\n",
      "tensor([[8, 8, 8, 8],\n",
      "        [8, 8, 8, 8],\n",
      "        [8, 8, 8, 8]])\n",
      "Diension: 2\n",
      "Shape: torch.Size([3, 4]) (Dimensions of the tensor)\n",
      "Element size: 8 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "full_tensor: torch.Tensor = torch.full(size=(3, 4), fill_value=8)\n",
    "print(f\"Full tensor:\\n{full_tensor}\")\n",
    "print(f\"Diension: {ones_like.ndim}\")\n",
    "print(f\"Shape: {full_tensor.shape} (Dimensions of the tensor)\")\n",
    "print(f\"Element size: {full_tensor.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Linspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n"
     ]
    }
   ],
   "source": [
    "x: torch.Tensor = torch.linspace(start=0, end=10, steps=5)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tensor:\n",
      "tensor([[0.3853, 0.9431],\n",
      "        [0.6344, 0.1645],\n",
      "        [0.5927, 0.4712],\n",
      "        [0.1956, 0.7791]])\n",
      "Data type: torch.float32\n",
      "Element size: 4 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "sample: torch.Tensor = torch.rand(size=(4, 2))\n",
    "print(f\"Sample tensor:\\n{sample}\")\n",
    "print(f\"Data type: {sample.dtype}\")\n",
    "print(f\"Element size: {sample.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tensor:\n",
      "tensor([[0.0371, 0.2705],\n",
      "        [0.8477, 0.8530],\n",
      "        [0.9673, 0.2808],\n",
      "        [0.1572, 0.2422]], dtype=torch.float16)\n",
      "Data type: torch.float16\n",
      "Element size: 2 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "sample: torch.Tensor = torch.rand(size=(4, 2), dtype=torch.float16)\n",
    "print(f\"Sample tensor:\\n{sample}\")\n",
    "print(f\"Data type: {sample.dtype}\")\n",
    "print(f\"Element size: {sample.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tensor:\n",
      "tensor([[0.0368, 0.9370],\n",
      "        [0.7524, 0.2547],\n",
      "        [0.7730, 0.8342],\n",
      "        [0.5603, 0.7122]], dtype=torch.float64)\n",
      "Data type: torch.float64\n",
      "Element size: 8 bytes (Size of each element)\n"
     ]
    }
   ],
   "source": [
    "sample: torch.Tensor = torch.rand(size=(4, 2), dtype=torch.float64)\n",
    "print(f\"Sample tensor:\\n{sample}\")\n",
    "print(f\"Data type: {sample.dtype}\")\n",
    "print(f\"Element size: {sample.element_size()} bytes (Size of each element)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Change Data Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "x: torch.Tensor = torch.arange(start=0, end=10, step=1)\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x: torch.Tensor = x.type(dtype=torch.float32)\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting information about a tensor\n",
    "1. **Shape**\n",
    "2. **Dtype**\n",
    "3. **Device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some tensor:\n",
      "tensor([[0.8568, 0.2853, 0.6356, 0.4534],\n",
      "        [0.4567, 0.5824, 0.8492, 0.0154],\n",
      "        [0.1801, 0.3131, 0.2498, 0.1441]])\n",
      "Shape: torch.Size([3, 4])\n",
      "Dtype: torch.float32\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "some_tensor: torch.Tensor = torch.rand(size=(3, 4))\n",
    "print(f\"Some tensor:\\n{some_tensor}\")\n",
    "print(f\"Shape: {some_tensor.shape}\")\n",
    "print(f\"Dtype: {some_tensor.dtype}\")\n",
    "print(f\"Device: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Operations (Manipulate Tensors)\n",
    "1. **Addition**\n",
    "2. **Subtraction**\n",
    "3. **Multiplication**\n",
    "4. **Division**\n",
    "5. **Dot Product**\n",
    "6. **Transpose**\n",
    "7. **Matrix Multiplication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n",
      "torch.int64\n",
      "torch.Size([3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Addition of Tensors\n",
    "a: torch.Tensor = torch.tensor(data=[1, 2, 3])\n",
    "b: torch.Tensor = torch.tensor(data=[4, 5, 6])\n",
    "c: torch.Tensor = a + b\n",
    "print(c)\n",
    "print(c.dtype)\n",
    "print(c.shape)\n",
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3, -3, -3])\n",
      "torch.int64\n",
      "torch.Size([3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Subraction of Tensors\n",
    "a: torch.Tensor = torch.tensor(data=[1, 2, 3])\n",
    "b: torch.Tensor = torch.tensor(data=[4, 5, 6])\n",
    "c: torch.Tensor = a - b\n",
    "print(c)\n",
    "print(c.dtype)\n",
    "print(c.shape)\n",
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 10, 18])\n",
      "torch.int64\n",
      "torch.Size([3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Multiplication of Tensors\n",
    "a: torch.Tensor = torch.tensor(data=[1, 2, 3])\n",
    "b: torch.Tensor = torch.tensor(data=[4, 5, 6])\n",
    "c: torch.Tensor = a * b\n",
    "print(c)\n",
    "print(c.dtype)\n",
    "print(c.shape)\n",
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2500, 0.4000, 0.5000])\n",
      "torch.float32\n",
      "torch.Size([3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Division of Tensors\n",
    "a: torch.Tensor = torch.tensor(data=[1, 2, 3])\n",
    "b: torch.Tensor = torch.tensor(data=[4, 5, 6])\n",
    "c: torch.Tensor = a / b\n",
    "print(c)\n",
    "print(c.dtype)\n",
    "print(c.shape)\n",
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32)\n",
      "torch.int64\n",
      "torch.Size([])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Dot Product of Tensors\n",
    "a: torch.Tensor = torch.tensor(data=[1, 2, 3])\n",
    "b: torch.Tensor = torch.tensor(data=[4, 5, 6])\n",
    "c: torch.Tensor = torch.dot(input=a, tensor=b)\n",
    "print(c)\n",
    "print(c.dtype)\n",
    "print(c.shape)\n",
    "print(c.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([[1, 4, 7],\n",
      "        [2, 5, 8],\n",
      "        [3, 6, 9]])\n",
      "torch.int64\n",
      "torch.Size([3, 3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Transpose of Tensors\n",
    "a: torch.Tensor = torch.tensor(data=[[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "b: torch.Tensor = torch.transpose(input=a, dim0=0, dim1=1)\n",
    "print(a)\n",
    "print(b)\n",
    "print(b.dtype)\n",
    "print(b.shape)\n",
    "print(b.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-zqkb-BGY-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
