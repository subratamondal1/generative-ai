{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrying with `backoff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI, RateLimitError, APITimeoutError\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__aenter__',\n",
       " '__aexit__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_base_url',\n",
       " '_build_headers',\n",
       " '_build_request',\n",
       " '_calculate_retry_timeout',\n",
       " '_client',\n",
       " '_custom_headers',\n",
       " '_custom_query',\n",
       " '_default_stream_cls',\n",
       " '_enforce_trailing_slash',\n",
       " '_idempotency_header',\n",
       " '_idempotency_key',\n",
       " '_limits',\n",
       " '_make_sse_decoder',\n",
       " '_make_status_error',\n",
       " '_make_status_error_from_response',\n",
       " '_maybe_override_cast_to',\n",
       " '_parse_retry_after_header',\n",
       " '_platform',\n",
       " '_prepare_options',\n",
       " '_prepare_request',\n",
       " '_prepare_url',\n",
       " '_process_response',\n",
       " '_process_response_data',\n",
       " '_proxies',\n",
       " '_request',\n",
       " '_request_api_list',\n",
       " '_retry_request',\n",
       " '_serialize_multipartform',\n",
       " '_should_retry',\n",
       " '_should_stream_response_body',\n",
       " '_strict_response_validation',\n",
       " '_transport',\n",
       " '_validate_headers',\n",
       " '_version',\n",
       " 'api_key',\n",
       " 'audio',\n",
       " 'auth_headers',\n",
       " 'base_url',\n",
       " 'batches',\n",
       " 'beta',\n",
       " 'chat',\n",
       " 'close',\n",
       " 'completions',\n",
       " 'copy',\n",
       " 'custom_auth',\n",
       " 'default_headers',\n",
       " 'default_query',\n",
       " 'delete',\n",
       " 'embeddings',\n",
       " 'files',\n",
       " 'fine_tuning',\n",
       " 'get',\n",
       " 'get_api_list',\n",
       " 'images',\n",
       " 'is_closed',\n",
       " 'max_retries',\n",
       " 'models',\n",
       " 'moderations',\n",
       " 'organization',\n",
       " 'patch',\n",
       " 'platform_headers',\n",
       " 'post',\n",
       " 'project',\n",
       " 'put',\n",
       " 'qs',\n",
       " 'request',\n",
       " 'timeout',\n",
       " 'uploads',\n",
       " 'user_agent',\n",
       " 'with_options',\n",
       " 'with_raw_response',\n",
       " 'with_streaming_response']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = AsyncOpenAI()\n",
    "\n",
    "GPT_4O_MINI = \"gpt-4o-mini\"\n",
    "\n",
    "dir(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_async',\n",
       " '_common',\n",
       " '_decorator',\n",
       " '_jitter',\n",
       " '_sync',\n",
       " '_typing',\n",
       " '_wait_gen',\n",
       " 'constant',\n",
       " 'expo',\n",
       " 'fibo',\n",
       " 'full_jitter',\n",
       " 'on_exception',\n",
       " 'on_predicate',\n",
       " 'random_jitter',\n",
       " 'runtime']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import backoff\n",
    "\n",
    "dir(backoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AXNfIZ3kxZJUGI45HW4yRb4WRlqPL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732519156, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_3de1288069', usage=CompletionUsage(completion_tokens=9, prompt_tokens=12, total_tokens=21, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RETRY this Function Call\n",
    "await client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=[dict(role=\"user\", content=\"Hey! Mista!\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import backoff\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "@wraps(wrapped=client.chat.completions.create)\n",
    "@backoff.on_exception(\n",
    "    wait_gen=backoff.expo, exception=(RateLimitError, APITimeoutError), max_time=60\n",
    ")\n",
    "async def do_call(*, model, messages, **kwargs) -> None:\n",
    "    await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Breakdown:\n",
    "\n",
    "#### **1. Importing Modules**\n",
    "\n",
    "```python\n",
    "import backoff\n",
    "from functools import wraps\n",
    "```\n",
    "\n",
    "- **`functools.wraps`**: A decorator for preserving the metadata (like the name, docstring, etc.) of the wrapped function when wrapping it with another function.\n",
    "- **`backoff`**: A library for retrying a function with an exponential backoff delay when specific exceptions occur.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. The `@wraps` Decorator**\n",
    "\n",
    "```python\n",
    "@wraps(wrapped=client.chat.completions.create)\n",
    "```\n",
    "\n",
    "- **Purpose**: Ensures that `do_call` retains the attributes (e.g., `__name__`, `__doc__`) of the `client.chat.completions.create` method.\n",
    "- **Why itâ€™s needed**: Without `@wraps`, the `do_call` function would lose its identity and show up as a generic wrapper function in logs or debugging.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. The `@backoff.on_exception` Decorator**\n",
    "\n",
    "```python\n",
    "@backoff.on_exception(\n",
    "    wait_gen=backoff.expo, exception=(RateLimitError, APITimeoutError), max_time=60\n",
    ")\n",
    "```\n",
    "\n",
    "- **Purpose**: Automatically retries the decorated function (`do_call`) when certain exceptions occur.\n",
    "- **Parameters**:\n",
    "  - `wait_gen=backoff.expo`: Uses exponential backoff for retry intervals (e.g., 1s, 2s, 4s, etc.).\n",
    "  - `exception=(RateLimitError, APITimeoutError)`: Specifies the exceptions that trigger the retry mechanism.\n",
    "  - `max_time=60`: Limits the retry attempts to a maximum of 60 seconds.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. The `do_call` Function**\n",
    "\n",
    "```python\n",
    "async def do_call(*, model, messages, **kwargs) -> None:\n",
    "    await client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **Async Function**: `async def` indicates that this is an asynchronous function.\n",
    "- **Arguments**:\n",
    "  - `model`, `messages`: Required keyword arguments for the function.\n",
    "  - `**kwargs`: Additional optional keyword arguments.\n",
    "- **Action**: Calls `client.chat.completions.create` asynchronously, passing along `model` and `messages`.\n",
    "\n",
    "---\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "1. **Retry on Exceptions**:\n",
    "   - If `client.chat.completions.create` raises either a `RateLimitError` or `APITimeoutError`, the `backoff` library retries the `do_call` function after an exponentially increasing delay.\n",
    "   - The retries stop after 60 seconds (due to `max_time=60`).\n",
    "\n",
    "2. **Metadata Preservation**:\n",
    "   - The `@wraps` decorator ensures `do_call` appears identical to `client.chat.completions.create` in terms of metadata. This is helpful for debugging, logging, and documentation purposes.\n",
    "\n",
    "3. **Asynchronous Execution**:\n",
    "   - `do_call` is designed for asynchronous workflows, making it suitable for non-blocking operations in an event loop (e.g., in frameworks like `asyncio` or `FastAPI`).\n",
    "\n",
    "---\n",
    "\n",
    "### Notes:\n",
    "\n",
    "- **Using `@wraps`**:\n",
    "  - When you wrap a function with a decorator, the decorated function usually loses its metadata.\n",
    "  - `functools.wraps` fixes this by copying the original function's metadata to the wrapper function.\n",
    "\n",
    "- **Using `backoff`**:\n",
    "  - The `backoff.on_exception` decorator simplifies adding retry logic.\n",
    "  - Exponential backoff prevents overwhelming the server during retries by gradually increasing the delay between attempts.\n",
    "\n",
    "- **Error Handling**:\n",
    "  - By specifying exceptions (`RateLimitError, APITimeoutError`), only those errors trigger the retry logic, preventing unnecessary retries for other failures.\n",
    "\n",
    "- **Async Context**:\n",
    "  - The `async` keyword allows the function to perform non-blocking calls, ideal for I/O-bound tasks like API calls.\n",
    "\n",
    "---\n",
    "\n",
    "This code block is a robust way to handle retries for API calls, especially when working in an asynchronous context and dealing with rate-limiting or timeout errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-zqkb-BGY-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
