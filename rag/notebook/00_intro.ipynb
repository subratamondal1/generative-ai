{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load API KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_base_url',\n",
       " '_build_headers',\n",
       " '_build_request',\n",
       " '_calculate_retry_timeout',\n",
       " '_client',\n",
       " '_custom_headers',\n",
       " '_custom_query',\n",
       " '_default_stream_cls',\n",
       " '_enforce_trailing_slash',\n",
       " '_idempotency_header',\n",
       " '_idempotency_key',\n",
       " '_limits',\n",
       " '_make_sse_decoder',\n",
       " '_make_status_error',\n",
       " '_make_status_error_from_response',\n",
       " '_maybe_override_cast_to',\n",
       " '_parse_retry_after_header',\n",
       " '_platform',\n",
       " '_prepare_options',\n",
       " '_prepare_request',\n",
       " '_prepare_url',\n",
       " '_process_response',\n",
       " '_process_response_data',\n",
       " '_proxies',\n",
       " '_request',\n",
       " '_request_api_list',\n",
       " '_retry_request',\n",
       " '_serialize_multipartform',\n",
       " '_should_retry',\n",
       " '_should_stream_response_body',\n",
       " '_strict_response_validation',\n",
       " '_transport',\n",
       " '_validate_headers',\n",
       " '_version',\n",
       " 'api_key',\n",
       " 'audio',\n",
       " 'auth_headers',\n",
       " 'base_url',\n",
       " 'batches',\n",
       " 'beta',\n",
       " 'chat',\n",
       " 'close',\n",
       " 'completions',\n",
       " 'copy',\n",
       " 'custom_auth',\n",
       " 'default_headers',\n",
       " 'default_query',\n",
       " 'delete',\n",
       " 'embeddings',\n",
       " 'files',\n",
       " 'fine_tuning',\n",
       " 'get',\n",
       " 'get_api_list',\n",
       " 'images',\n",
       " 'is_closed',\n",
       " 'max_retries',\n",
       " 'models',\n",
       " 'moderations',\n",
       " 'organization',\n",
       " 'patch',\n",
       " 'platform_headers',\n",
       " 'post',\n",
       " 'project',\n",
       " 'put',\n",
       " 'qs',\n",
       " 'request',\n",
       " 'timeout',\n",
       " 'uploads',\n",
       " 'user_agent',\n",
       " 'with_options',\n",
       " 'with_raw_response',\n",
       " 'with_streaming_response']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI()\n",
    "dir(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on OpenAI in module openai object:\n",
      "\n",
      "class OpenAI(openai._base_client.SyncAPIClient)\n",
      " |  OpenAI(*, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'Union[float, Timeout, None, NotGiven]' = NOT_GIVEN, max_retries: 'int' = 2, default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, http_client: 'httpx.Client | None' = None, _strict_response_validation: 'bool' = False) -> 'None'\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      OpenAI\n",
      " |      openai._base_client.SyncAPIClient\n",
      " |      openai._base_client.BaseClient\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'Union[float, Timeout, None, NotGiven]' = NOT_GIVEN, max_retries: 'int' = 2, default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, http_client: 'httpx.Client | None' = None, _strict_response_validation: 'bool' = False) -> 'None' from openai._client.OpenAI\n",
      " |      Construct a new synchronous openai client instance.\n",
      " |\n",
      " |      This automatically infers the following arguments from their corresponding environment variables if they are not provided:\n",
      " |      - `api_key` from `OPENAI_API_KEY`\n",
      " |      - `organization` from `OPENAI_ORG_ID`\n",
      " |      - `project` from `OPENAI_PROJECT_ID`\n",
      " |\n",
      " |  copy(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'float | Timeout | None | NotGiven' = NOT_GIVEN, http_client: 'httpx.Client | None' = None, max_retries: 'int | NotGiven' = NOT_GIVEN, default_headers: 'Mapping[str, str] | None' = None, set_default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, set_default_query: 'Mapping[str, object] | None' = None, _extra_kwargs: 'Mapping[str, Any]' = {}) -> 'Self' from openai._client.OpenAI\n",
      " |      Create a new client instance re-using the same options given to the current client with optional overriding.\n",
      " |\n",
      " |  with_options = copy(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'float | Timeout | None | NotGiven' = NOT_GIVEN, http_client: 'httpx.Client | None' = None, max_retries: 'int | NotGiven' = NOT_GIVEN, default_headers: 'Mapping[str, str] | None' = None, set_default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, set_default_query: 'Mapping[str, object] | None' = None, _extra_kwargs: 'Mapping[str, Any]' = {}) -> 'Self'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  auth_headers\n",
      " |\n",
      " |  default_headers\n",
      " |\n",
      " |  qs\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'api_key': 'str', 'audio': 'resources.Audio', 'batc...\n",
      " |\n",
      " |  __parameters__ = ()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._base_client.SyncAPIClient:\n",
      " |\n",
      " |  __enter__(self: '_T') -> '_T'\n",
      " |\n",
      " |  __exit__(self, exc_type: 'type[BaseException] | None', exc: 'BaseException | None', exc_tb: 'TracebackType | None') -> 'None'\n",
      " |\n",
      " |  close(self) -> 'None'\n",
      " |      Close the underlying HTTPX client.\n",
      " |\n",
      " |      The client will *not* be usable after this.\n",
      " |\n",
      " |  delete(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  get(self, path: 'str', *, cast_to: 'Type[ResponseT]', options: 'RequestOptions' = {}, stream: 'bool' = False, stream_cls: 'type[_StreamT] | None' = None) -> 'ResponseT | _StreamT'\n",
      " |\n",
      " |  get_api_list(self, path: 'str', *, model: 'Type[object]', page: 'Type[SyncPageT]', body: 'Body | None' = None, options: 'RequestOptions' = {}, method: 'str' = 'get') -> 'SyncPageT'\n",
      " |\n",
      " |  is_closed(self) -> 'bool'\n",
      " |\n",
      " |  patch(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  post(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}, files: 'RequestFiles | None' = None, stream: 'bool' = False, stream_cls: 'type[_StreamT] | None' = None) -> 'ResponseT | _StreamT'\n",
      " |\n",
      " |  put(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, files: 'RequestFiles | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  request(self, cast_to: 'Type[ResponseT]', options: 'FinalRequestOptions', remaining_retries: 'Optional[int]' = None, *, stream: 'bool' = False, stream_cls: 'type[_StreamT] | None' = None) -> 'ResponseT | _StreamT'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from openai._base_client.SyncAPIClient:\n",
      " |\n",
      " |  __orig_bases__ = (openai._base_client.BaseClient[httpx.Client, openai....\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  platform_headers(self) -> 'Dict[str, str]'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  custom_auth\n",
      " |\n",
      " |  default_query\n",
      " |\n",
      " |  user_agent\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  base_url\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(request=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_4O_MINI = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _msg(role: str, content: str) -> dict[str, str]:\n",
    "    return {\"role\": role, \"content\": content}\n",
    "\n",
    "\n",
    "def _system(content: str) -> dict[str, str]:\n",
    "    return _msg(role=\"system\", content=content)\n",
    "\n",
    "\n",
    "def _user(content: str) -> dict[str, str]:\n",
    "    return _msg(role=\"user\", content=content)\n",
    "\n",
    "\n",
    "def _assistant(content: str) -> dict[str, str]:\n",
    "    return _msg(role=\"assistant\", content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'What is Python?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Python is a programming language that lets you work quickly and integrate systems more effectively.'},\n",
       " {'role': 'user', 'content': 'Why is that so???'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history: list[dict[str, str]] = [\n",
    "    _system(content=\"You are a helpful assistant.\"),\n",
    "    _user(content=\"What is Python?\"),\n",
    "    _assistant(\n",
    "        content=\"Python is a programming language that lets you work quickly and integrate systems more effectively.\"\n",
    "    ),\n",
    "    _user(content=\"Why is that so???\"),\n",
    "]\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "completeion = client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AVAy3ncDlXwQoy2oZq7UX6Dsi20tf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Python is known for several key reasons that contribute to its appeal and effectiveness:\\n\\n1. **Ease of Learning and Readability**: Python has a clean and straightforward syntax that resembles plain English, making it accessible to beginners. This readability allows developers to easily understand and maintain code.\\n\\n2. **Versatile and Powerful**: Python is a general-purpose language, meaning it can be used for various applications, including web development, data analysis, artificial intelligence, scientific computing, automation, and more.\\n\\n3. **Rich Ecosystem of Libraries and Frameworks**: Python has a vast collection of libraries and frameworks (such as NumPy for numerical computing, Pandas for data analysis, Flask/Django for web development, TensorFlow/PyTorch for machine learning, etc.) that extend its functionality and allow developers to implement complex tasks more easily.\\n\\n4. **Cross-Platform Compatibility**: Python runs on various operating systems, including Windows, macOS, and Linux, making it versatile for development across different environments.\\n\\n5. **Strong Community Support**: Python has a large, active community of users and developers who contribute to its development, provide support through forums, write tutorials, and create open-source projects, which makes learning and problem-solving easier.\\n\\n6. **Integration Capabilities**: Python can easily integrate with other languages and technologies, allowing it to be used in existing applications and systems.\\n\\n7. **Dynamic Typing and Easy Prototyping**: Python uses dynamic typing, which allows developers to write less code and build prototypes rapidly, making it ideal for startups and projects that require quick iterations.\\n\\nAll these aspects contribute to Python's popularity among professional developers and hobbyists alike, which has led to its widespread adoption in various industries.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1731993691, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0ba0d124f1', usage=CompletionUsage(completion_tokens=347, prompt_tokens=50, total_tokens=397, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(object=completeion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_check_frozen',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " '_request_id',\n",
       " 'choices',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'created',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'id',\n",
       " 'json',\n",
       " 'model',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'object',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'service_tier',\n",
       " 'system_fingerprint',\n",
       " 'to_dict',\n",
       " 'to_json',\n",
       " 'update_forward_refs',\n",
       " 'usage',\n",
       " 'validate']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(completeion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Python is known for several key reasons that contribute to its appeal and '\n",
      " 'effectiveness:\\n'\n",
      " '\\n'\n",
      " '1. **Ease of Learning and Readability**: Python has a clean and '\n",
      " 'straightforward syntax that resembles plain English, making it accessible to '\n",
      " 'beginners. This readability allows developers to easily understand and '\n",
      " 'maintain code.\\n'\n",
      " '\\n'\n",
      " '2. **Versatile and Powerful**: Python is a general-purpose language, meaning '\n",
      " 'it can be used for various applications, including web development, data '\n",
      " 'analysis, artificial intelligence, scientific computing, automation, and '\n",
      " 'more.\\n'\n",
      " '\\n'\n",
      " '3. **Rich Ecosystem of Libraries and Frameworks**: Python has a vast '\n",
      " 'collection of libraries and frameworks (such as NumPy for numerical '\n",
      " 'computing, Pandas for data analysis, Flask/Django for web development, '\n",
      " 'TensorFlow/PyTorch for machine learning, etc.) that extend its functionality '\n",
      " 'and allow developers to implement complex tasks more easily.\\n'\n",
      " '\\n'\n",
      " '4. **Cross-Platform Compatibility**: Python runs on various operating '\n",
      " 'systems, including Windows, macOS, and Linux, making it versatile for '\n",
      " 'development across different environments.\\n'\n",
      " '\\n'\n",
      " '5. **Strong Community Support**: Python has a large, active community of '\n",
      " 'users and developers who contribute to its development, provide support '\n",
      " 'through forums, write tutorials, and create open-source projects, which '\n",
      " 'makes learning and problem-solving easier.\\n'\n",
      " '\\n'\n",
      " '6. **Integration Capabilities**: Python can easily integrate with other '\n",
      " 'languages and technologies, allowing it to be used in existing applications '\n",
      " 'and systems.\\n'\n",
      " '\\n'\n",
      " '7. **Dynamic Typing and Easy Prototyping**: Python uses dynamic typing, '\n",
      " 'which allows developers to write less code and build prototypes rapidly, '\n",
      " 'making it ideal for startups and projects that require quick iterations.\\n'\n",
      " '\\n'\n",
      " \"All these aspects contribute to Python's popularity among professional \"\n",
      " 'developers and hobbyists alike, which has led to its widespread adoption in '\n",
      " 'various industries.')\n"
     ]
    }
   ],
   "source": [
    "pprint(completeion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append(_assistant(content=completeion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.append(_user(content=\"What about Rust?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      " {'content': 'What is Python?', 'role': 'user'},\n",
      " {'content': 'Python is a programming language that lets you work quickly and '\n",
      "             'integrate systems more effectively.',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Why is that so???', 'role': 'user'},\n",
      " {'content': 'Python is known for several key reasons that contribute to its '\n",
      "             'appeal and effectiveness:\\n'\n",
      "             '\\n'\n",
      "             '1. **Ease of Learning and Readability**: Python has a clean and '\n",
      "             'straightforward syntax that resembles plain English, making it '\n",
      "             'accessible to beginners. This readability allows developers to '\n",
      "             'easily understand and maintain code.\\n'\n",
      "             '\\n'\n",
      "             '2. **Versatile and Powerful**: Python is a general-purpose '\n",
      "             'language, meaning it can be used for various applications, '\n",
      "             'including web development, data analysis, artificial '\n",
      "             'intelligence, scientific computing, automation, and more.\\n'\n",
      "             '\\n'\n",
      "             '3. **Rich Ecosystem of Libraries and Frameworks**: Python has a '\n",
      "             'vast collection of libraries and frameworks (such as NumPy for '\n",
      "             'numerical computing, Pandas for data analysis, Flask/Django for '\n",
      "             'web development, TensorFlow/PyTorch for machine learning, etc.) '\n",
      "             'that extend its functionality and allow developers to implement '\n",
      "             'complex tasks more easily.\\n'\n",
      "             '\\n'\n",
      "             '4. **Cross-Platform Compatibility**: Python runs on various '\n",
      "             'operating systems, including Windows, macOS, and Linux, making '\n",
      "             'it versatile for development across different environments.\\n'\n",
      "             '\\n'\n",
      "             '5. **Strong Community Support**: Python has a large, active '\n",
      "             'community of users and developers who contribute to its '\n",
      "             'development, provide support through forums, write tutorials, '\n",
      "             'and create open-source projects, which makes learning and '\n",
      "             'problem-solving easier.\\n'\n",
      "             '\\n'\n",
      "             '6. **Integration Capabilities**: Python can easily integrate '\n",
      "             'with other languages and technologies, allowing it to be used in '\n",
      "             'existing applications and systems.\\n'\n",
      "             '\\n'\n",
      "             '7. **Dynamic Typing and Easy Prototyping**: Python uses dynamic '\n",
      "             'typing, which allows developers to write less code and build '\n",
      "             'prototypes rapidly, making it ideal for startups and projects '\n",
      "             'that require quick iterations.\\n'\n",
      "             '\\n'\n",
      "             \"All these aspects contribute to Python's popularity among \"\n",
      "             'professional developers and hobbyists alike, which has led to '\n",
      "             'its widespread adoption in various industries.',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'What about Rust?', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AVB78yLllvzfE5psjLsep4o8ftSFA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Rust is a modern, systems programming language that emphasizes safety, concurrency, and performance. Here are some key features and reasons that make Rust notable:\\n\\n1. **Memory Safety**: Rust's primary feature is its emphasis on memory safety without the need for a garbage collector. It uses a unique ownership system that enforces rules at compile time, ensuring that references do not become dangling and that data races are eliminated.\\n\\n2. **Performance**: Rust is designed to be as fast as C and C++, often close to the performance of these languages. This makes it suitable for systems programming, game development, and other performance-critical applications.\\n\\n3. **Concurrency**: Rust's ownership model allows for safe concurrency. It enables developers to write concurrent code that is free from common concurrency bugs such as data races, making it easier to take advantage of multi-core processors.\\n\\n4. **Rich Type System**: Rust features a strong and expressive type system, including features like enums, pattern matching, and traits, which help in designing robust and maintainable software.\\n\\n5. **Cross-Platform**: Rust can compile to various platforms, including Windows, macOS, and Linux, making it a versatile choice for developing cross-platform applications.\\n\\n6. **Tooling and Ecosystem**: Rust comes with excellent tools like `Cargo` (the package manager and build system) and `rustfmt` (for code formatting). The Rust community has built a growing ecosystem of libraries and frameworks to facilitate various development tasks.\\n\\n7. **Community and Documentation**: The Rust community is known for being welcoming and helpful. The official documentation is comprehensive and well-written, which helps new developers learn Rust effectively.\\n\\n8. **Interoperability**: Rust can easily interface with C and other languages, making it a good choice for extending existing codebases or writing high-performance components in a system dominated by another language.\\n\\nBecause of these features, Rust has gained popularity in areas such as systems programming, web assembly, embedded systems, and more, particularly where safety and performance are critical. It is seen as a modern alternative to C and C++ for many applications.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1731994254, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0705bf87c0', usage=CompletionUsage(completion_tokens=425, prompt_tokens=409, total_tokens=834, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "completeion = client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "pprint(completeion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Rust is a modern, systems programming language that emphasizes safety, '\n",
      " 'concurrency, and performance. Here are some key features and reasons that '\n",
      " 'make Rust notable:\\n'\n",
      " '\\n'\n",
      " \"1. **Memory Safety**: Rust's primary feature is its emphasis on memory \"\n",
      " 'safety without the need for a garbage collector. It uses a unique ownership '\n",
      " 'system that enforces rules at compile time, ensuring that references do not '\n",
      " 'become dangling and that data races are eliminated.\\n'\n",
      " '\\n'\n",
      " '2. **Performance**: Rust is designed to be as fast as C and C++, often close '\n",
      " 'to the performance of these languages. This makes it suitable for systems '\n",
      " 'programming, game development, and other performance-critical applications.\\n'\n",
      " '\\n'\n",
      " \"3. **Concurrency**: Rust's ownership model allows for safe concurrency. It \"\n",
      " 'enables developers to write concurrent code that is free from common '\n",
      " 'concurrency bugs such as data races, making it easier to take advantage of '\n",
      " 'multi-core processors.\\n'\n",
      " '\\n'\n",
      " '4. **Rich Type System**: Rust features a strong and expressive type system, '\n",
      " 'including features like enums, pattern matching, and traits, which help in '\n",
      " 'designing robust and maintainable software.\\n'\n",
      " '\\n'\n",
      " '5. **Cross-Platform**: Rust can compile to various platforms, including '\n",
      " 'Windows, macOS, and Linux, making it a versatile choice for developing '\n",
      " 'cross-platform applications.\\n'\n",
      " '\\n'\n",
      " '6. **Tooling and Ecosystem**: Rust comes with excellent tools like `Cargo` '\n",
      " '(the package manager and build system) and `rustfmt` (for code formatting). '\n",
      " 'The Rust community has built a growing ecosystem of libraries and frameworks '\n",
      " 'to facilitate various development tasks.\\n'\n",
      " '\\n'\n",
      " '7. **Community and Documentation**: The Rust community is known for being '\n",
      " 'welcoming and helpful. The official documentation is comprehensive and '\n",
      " 'well-written, which helps new developers learn Rust effectively.\\n'\n",
      " '\\n'\n",
      " '8. **Interoperability**: Rust can easily interface with C and other '\n",
      " 'languages, making it a good choice for extending existing codebases or '\n",
      " 'writing high-performance components in a system dominated by another '\n",
      " 'language.\\n'\n",
      " '\\n'\n",
      " 'Because of these features, Rust has gained popularity in areas such as '\n",
      " 'systems programming, web assembly, embedded systems, and more, particularly '\n",
      " 'where safety and performance are critical. It is seen as a modern '\n",
      " 'alternative to C and C++ for many applications.')\n"
     ]
    }
   ],
   "source": [
    "pprint(completeion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "CPU times: user 2.46 ms, sys: 1.58 ms, total: 4.04 ms\n",
      "Wall time: 29.4 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:3: RuntimeWarning: coroutine 'AsyncCompletions.create' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<timed exec>:10: RuntimeWarning: coroutine 'AsyncCompletions.create' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "<timed exec>:17: RuntimeWarning: coroutine 'AsyncCompletions.create' was never awaited\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(1)\n",
    "\n",
    "completeion1 = client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(2)\n",
    "\n",
    "completeion2 = client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(3)\n",
    "\n",
    "completeion3 = client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__aenter__',\n",
       " '__aexit__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_base_url',\n",
       " '_build_headers',\n",
       " '_build_request',\n",
       " '_calculate_retry_timeout',\n",
       " '_client',\n",
       " '_custom_headers',\n",
       " '_custom_query',\n",
       " '_default_stream_cls',\n",
       " '_enforce_trailing_slash',\n",
       " '_idempotency_header',\n",
       " '_idempotency_key',\n",
       " '_limits',\n",
       " '_make_sse_decoder',\n",
       " '_make_status_error',\n",
       " '_make_status_error_from_response',\n",
       " '_maybe_override_cast_to',\n",
       " '_parse_retry_after_header',\n",
       " '_platform',\n",
       " '_prepare_options',\n",
       " '_prepare_request',\n",
       " '_prepare_url',\n",
       " '_process_response',\n",
       " '_process_response_data',\n",
       " '_proxies',\n",
       " '_request',\n",
       " '_request_api_list',\n",
       " '_retry_request',\n",
       " '_serialize_multipartform',\n",
       " '_should_retry',\n",
       " '_should_stream_response_body',\n",
       " '_strict_response_validation',\n",
       " '_transport',\n",
       " '_validate_headers',\n",
       " '_version',\n",
       " 'api_key',\n",
       " 'audio',\n",
       " 'auth_headers',\n",
       " 'base_url',\n",
       " 'batches',\n",
       " 'beta',\n",
       " 'chat',\n",
       " 'close',\n",
       " 'completions',\n",
       " 'copy',\n",
       " 'custom_auth',\n",
       " 'default_headers',\n",
       " 'default_query',\n",
       " 'delete',\n",
       " 'embeddings',\n",
       " 'files',\n",
       " 'fine_tuning',\n",
       " 'get',\n",
       " 'get_api_list',\n",
       " 'images',\n",
       " 'is_closed',\n",
       " 'max_retries',\n",
       " 'models',\n",
       " 'moderations',\n",
       " 'organization',\n",
       " 'patch',\n",
       " 'platform_headers',\n",
       " 'post',\n",
       " 'project',\n",
       " 'put',\n",
       " 'qs',\n",
       " 'request',\n",
       " 'timeout',\n",
       " 'uploads',\n",
       " 'user_agent',\n",
       " 'with_options',\n",
       " 'with_raw_response',\n",
       " 'with_streaming_response']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "\n",
    "dir(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on AsyncOpenAI in module openai object:\n",
      "\n",
      "class AsyncOpenAI(openai._base_client.AsyncAPIClient)\n",
      " |  AsyncOpenAI(*, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'Union[float, Timeout, None, NotGiven]' = NOT_GIVEN, max_retries: 'int' = 2, default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, http_client: 'httpx.AsyncClient | None' = None, _strict_response_validation: 'bool' = False) -> 'None'\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      AsyncOpenAI\n",
      " |      openai._base_client.AsyncAPIClient\n",
      " |      openai._base_client.BaseClient\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'Union[float, Timeout, None, NotGiven]' = NOT_GIVEN, max_retries: 'int' = 2, default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, http_client: 'httpx.AsyncClient | None' = None, _strict_response_validation: 'bool' = False) -> 'None' from openai._client.AsyncOpenAI\n",
      " |      Construct a new async openai client instance.\n",
      " |\n",
      " |      This automatically infers the following arguments from their corresponding environment variables if they are not provided:\n",
      " |      - `api_key` from `OPENAI_API_KEY`\n",
      " |      - `organization` from `OPENAI_ORG_ID`\n",
      " |      - `project` from `OPENAI_PROJECT_ID`\n",
      " |\n",
      " |  copy(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'float | Timeout | None | NotGiven' = NOT_GIVEN, http_client: 'httpx.AsyncClient | None' = None, max_retries: 'int | NotGiven' = NOT_GIVEN, default_headers: 'Mapping[str, str] | None' = None, set_default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, set_default_query: 'Mapping[str, object] | None' = None, _extra_kwargs: 'Mapping[str, Any]' = {}) -> 'Self' from openai._client.AsyncOpenAI\n",
      " |      Create a new client instance re-using the same options given to the current client with optional overriding.\n",
      " |\n",
      " |  with_options = copy(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'float | Timeout | None | NotGiven' = NOT_GIVEN, http_client: 'httpx.AsyncClient | None' = None, max_retries: 'int | NotGiven' = NOT_GIVEN, default_headers: 'Mapping[str, str] | None' = None, set_default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, set_default_query: 'Mapping[str, object] | None' = None, _extra_kwargs: 'Mapping[str, Any]' = {}) -> 'Self'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  auth_headers\n",
      " |\n",
      " |  default_headers\n",
      " |\n",
      " |  qs\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'api_key': 'str', 'audio': 'resources.AsyncAudio', ...\n",
      " |\n",
      " |  __parameters__ = ()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._base_client.AsyncAPIClient:\n",
      " |\n",
      " |  async __aenter__(self: '_T') -> '_T'\n",
      " |\n",
      " |  async __aexit__(self, exc_type: 'type[BaseException] | None', exc: 'BaseException | None', exc_tb: 'TracebackType | None') -> 'None'\n",
      " |\n",
      " |  async close(self) -> 'None'\n",
      " |      Close the underlying HTTPX client.\n",
      " |\n",
      " |      The client will *not* be usable after this.\n",
      " |\n",
      " |  async delete(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  async get(self, path: 'str', *, cast_to: 'Type[ResponseT]', options: 'RequestOptions' = {}, stream: 'bool' = False, stream_cls: 'type[_AsyncStreamT] | None' = None) -> 'ResponseT | _AsyncStreamT'\n",
      " |\n",
      " |  get_api_list(self, path: 'str', *, model: 'Type[_T]', page: 'Type[AsyncPageT]', body: 'Body | None' = None, options: 'RequestOptions' = {}, method: 'str' = 'get') -> 'AsyncPaginator[_T, AsyncPageT]'\n",
      " |\n",
      " |  is_closed(self) -> 'bool'\n",
      " |\n",
      " |  async patch(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  async post(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, files: 'RequestFiles | None' = None, options: 'RequestOptions' = {}, stream: 'bool' = False, stream_cls: 'type[_AsyncStreamT] | None' = None) -> 'ResponseT | _AsyncStreamT'\n",
      " |\n",
      " |  async put(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, files: 'RequestFiles | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  async request(self, cast_to: 'Type[ResponseT]', options: 'FinalRequestOptions', *, stream: 'bool' = False, stream_cls: 'type[_AsyncStreamT] | None' = None, remaining_retries: 'Optional[int]' = None) -> 'ResponseT | _AsyncStreamT'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from openai._base_client.AsyncAPIClient:\n",
      " |\n",
      " |  __orig_bases__ = (openai._base_client.BaseClient[httpx.AsyncClient, op...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  platform_headers(self) -> 'Dict[str, str]'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  custom_auth\n",
      " |\n",
      " |  default_query\n",
      " |\n",
      " |  user_agent\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  base_url\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history: list[dict[str, str]] = [\n",
    "    _system(content=\"You are a helpful assistant.\"),\n",
    "    _user(content=\"What is Python?\"),\n",
    "    _assistant(\n",
    "        content=\"Python is a programming language that lets you work quickly and integrate systems more effectively.\"\n",
    "    ),\n",
    "    _user(content=\"Why is that so???\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = await client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    "    max_tokens=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "21.794078826904297\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(1)\n",
    "# Synchronous Code Execution due to await\n",
    "completion1 = await client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(2)\n",
    "\n",
    "# Synchronous Code Execution due to await\n",
    "completion2 = await client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(3)\n",
    "\n",
    "# Synchronous Code Execution due to await\n",
    "completion3 = await client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(4)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.0008597373962402344\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "print(1)\n",
    "# Asynchronous Code Execution due to no await\n",
    "completion1 = client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(2)\n",
    "\n",
    "# Asynchronous Code Execution due to no await\n",
    "completion2 = client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(3)\n",
    "\n",
    "# Asynchronous Code Execution due to no await\n",
    "completion3 = client.chat.completions.create(\n",
    "    model=GPT_4O_MINI,\n",
    "    messages=chat_history,\n",
    ")\n",
    "\n",
    "print(4)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25349.69273433167"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21.794078826904297 / 0.0008597373962402344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.875692844390869\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results = await asyncio.gather(completion1, completion2, completion3)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletion(id='chatcmpl-AVDRYv1ZlNWYVwCtL0UyErA3FcEcd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Python is considered a powerful and versatile programming language for several reasons:\\n\\n1. **Readability and Simplicity**: Python's syntax is designed to be clear and easy to read, which makes it accessible to beginners. Its indentation-based structure enforces a clean coding style.\\n\\n2. **Versatile Functionality**: Python can be used for a wide range of applications, from web development and data analysis to artificial intelligence and scientific computing.\\n\\n3. **Extensive Libraries and Frameworks**: Python has a rich ecosystem of libraries and frameworks, such as NumPy and pandas for data analysis, Django and Flask for web development, TensorFlow and PyTorch for machine learning, and many more. This makes it easier to implement complex functionalities without having to build everything from scratch.\\n\\n4. **Cross-Platform Compatibility**: Python is available on various platforms (Windows, macOS, Linux), allowing developers to write code that works on multiple operating systems.\\n\\n5. **Strong Community Support**: Python has a large and active community, which means there are many resources available, including documentation, tutorials, forums, and open-source projects that can help developers solve problems and improve their skills.\\n\\n6. **Interpreted Language**: As an interpreted language, Python allows for rapid development and testing. You can run code in an interactive shell, which speeds up the process of debugging and prototyping.\\n\\n7. **Multi-Paradigm Support**: Python supports multiple programming paradigms, including procedural, object-oriented, and functional programming, giving developers the flexibility to use the style that suits their needs.\\n\\n8. **Integration Capabilities**: Python can easily integrate with other languages (like C, C++, and Java) and technologies, enabling developers to leverage existing code and systems.\\n\\nThese features contribute to Python's popularity in various domains, making it a go-to language for developers, scientists, educators, and hobbyists alike.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732003208, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0705bf87c0', usage=CompletionUsage(completion_tokens=383, prompt_tokens=50, total_tokens=433, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))),\n",
       " ChatCompletion(id='chatcmpl-AVDRYnX2YdXuuIsac9RMS7foyAwW4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Python is often described as an easy language to learn and use for several reasons:\\n\\n1. **Readability**: Python emphasizes readability, allowing programmers to express concepts in fewer lines of code compared to many other languages. Its clean syntax makes it easier to understand and maintain code.\\n\\n2. **Simplicity**: The design of Python promotes a straightforward approach to programming. This lowers the barrier for beginners and allows experienced programmers to work more efficiently.\\n\\n3. **Versatile**: Python is a general-purpose programming language, which means it can be used for a wide variety of applications, from web development and data analysis to artificial intelligence and scientific computing.\\n\\n4. **Extensive Libraries**: Python offers a rich set of libraries and frameworks (like NumPy, pandas, TensorFlow, and Django) that facilitate complex tasks without needing to reinvent the wheel.\\n\\n5. **Community and Support**: Python has a large and active community, providing ample resources, documentation, and forums for help and collaboration. This contributes to a wealth of knowledge available to learners and experienced developers alike.\\n\\n6. **Cross-Platform**: Python runs on various platforms (Windows, macOS, Linux), allowing developers to write code that works across different operating systems without significant modification.\\n\\n7. **Interpreted Language**: Python code is executed line by line, which makes debugging easier, as you can quickly test and modify scripts in real-time.\\n\\n8. **Strong Typing**: While Python is dynamically typed (you don't need to declare variable types), its strong typing enforces type rules that help prevent many common programming errors.\\n\\nBecause of these features, Python is widely used in various fields, including data science, web development, automation, machine learning, and more, making it a popular choice for both beginners and experienced developers.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732003208, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0ba0d124f1', usage=CompletionUsage(completion_tokens=362, prompt_tokens=50, total_tokens=412, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))),\n",
       " ChatCompletion(id='chatcmpl-AVDRYi5JDBee3WswC3mINSE8s5HZm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Python is considered a powerful and versatile programming language for several reasons:\\n\\n1. **Readability and Simplicity**: Python's syntax is clear, concise, and easy to read, making it accessible for beginners and efficient for experienced programmers. This emphasis on readability allows developers to understand and maintain code more easily.\\n\\n2. **Versatile and General-Purpose**: Python can be used for a wide range of applications, including web development, data analysis, artificial intelligence, scientific computing, automation, and more. This versatility makes it a popular choice for many developers.\\n\\n3. **Rich Libraries and Frameworks**: Python has a vast ecosystem of libraries and frameworks that extend its capabilities. For example, libraries like NumPy and pandas are great for data manipulation and analysis, while frameworks like Django and Flask are used for web development.\\n\\n4. **Community Support**: Python has a large and active community, which means that there is a wealth of resources, tutorials, and documentation available. This community support can help developers find solutions to problems and share knowledge.\\n\\n5. **Cross-Platform Compatibility**: Python is platform-independent, meaning that it can run on various operating systems, including Windows, macOS, and Linux without modification.\\n\\n6. **Support for Multiple Programming Paradigms**: Python supports various programming styles, including procedural, object-oriented, and functional programming, giving developers flexibility in how they design their software.\\n\\n7. **Strong Integration Capabilities**: Python easily integrates with other languages and technologies, making it a great choice for projects that require system integration.\\n\\n8. **High Demand**: Python is one of the most in-demand programming languages in the job market, particularly in fields such as data science, machine learning, web development, and automation.\\n\\nThese factors contribute to Python's reputation as a language that enables rapid development and effective system integration, making it a preferred choice for many developers and organizations.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732003208, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0ba0d124f1', usage=CompletionUsage(completion_tokens=383, prompt_tokens=50, total_tokens=433, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Async Visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_tasks = []\n",
    "\n",
    "for i in range(10):\n",
    "    completion_task = client.chat.completions.create(\n",
    "        model=GPT_4O_MINI,\n",
    "        messages=chat_history,\n",
    "        max_tokens=50,\n",
    "    )\n",
    "\n",
    "    completion_tasks.append(completion_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(completion_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6972711086273193\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "results = await asyncio.gather(*completion_tasks)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Python is valued for several reasons:\\n'\n",
      " '\\n'\n",
      " \"1. **Readability and Simplicity**: Python's syntax is clear and \"\n",
      " 'straightforward, which makes it easier for beginners to learn and for '\n",
      " 'experienced developers to read and maintain code. This emphasis on code '\n",
      " 'readability encourages')\n"
     ]
    }
   ],
   "source": [
    "pprint(results[49].choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "68.03667879104614\n"
     ]
    }
   ],
   "source": [
    "# Synchronous Code Execution due to await\n",
    "start = time.time()\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    completion_task = await client.chat.completions.create(\n",
    "        model=GPT_4O_MINI,\n",
    "        messages=chat_history,\n",
    "        max_tokens=50,\n",
    "    )\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history: list[dict[str, str]] = [\n",
    "    _system(content=\"You are a helpful assistant.\"),\n",
    "    _user(content=\"What is Python?\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion_tasks = []\n",
    "\n",
    "for i in range(10):\n",
    "    completion_task = client.chat.completions.create(\n",
    "        model=GPT_4O_MINI,\n",
    "        messages=chat_history,\n",
    "        max_tokens=5,\n",
    "    )\n",
    "\n",
    "    completion_tasks.append(completion_task)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-zqkb-BGY-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
