{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__aenter__',\n",
       " '__aexit__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_base_url',\n",
       " '_build_headers',\n",
       " '_build_request',\n",
       " '_calculate_retry_timeout',\n",
       " '_client',\n",
       " '_custom_headers',\n",
       " '_custom_query',\n",
       " '_default_stream_cls',\n",
       " '_enforce_trailing_slash',\n",
       " '_idempotency_header',\n",
       " '_idempotency_key',\n",
       " '_limits',\n",
       " '_make_sse_decoder',\n",
       " '_make_status_error',\n",
       " '_make_status_error_from_response',\n",
       " '_maybe_override_cast_to',\n",
       " '_parse_retry_after_header',\n",
       " '_platform',\n",
       " '_prepare_options',\n",
       " '_prepare_request',\n",
       " '_prepare_url',\n",
       " '_process_response',\n",
       " '_process_response_data',\n",
       " '_proxies',\n",
       " '_request',\n",
       " '_request_api_list',\n",
       " '_retry_request',\n",
       " '_serialize_multipartform',\n",
       " '_should_retry',\n",
       " '_should_stream_response_body',\n",
       " '_strict_response_validation',\n",
       " '_transport',\n",
       " '_validate_headers',\n",
       " '_version',\n",
       " 'api_key',\n",
       " 'audio',\n",
       " 'auth_headers',\n",
       " 'base_url',\n",
       " 'batches',\n",
       " 'beta',\n",
       " 'chat',\n",
       " 'close',\n",
       " 'completions',\n",
       " 'copy',\n",
       " 'custom_auth',\n",
       " 'default_headers',\n",
       " 'default_query',\n",
       " 'delete',\n",
       " 'embeddings',\n",
       " 'files',\n",
       " 'fine_tuning',\n",
       " 'get',\n",
       " 'get_api_list',\n",
       " 'images',\n",
       " 'is_closed',\n",
       " 'max_retries',\n",
       " 'models',\n",
       " 'moderations',\n",
       " 'organization',\n",
       " 'patch',\n",
       " 'platform_headers',\n",
       " 'post',\n",
       " 'project',\n",
       " 'put',\n",
       " 'qs',\n",
       " 'request',\n",
       " 'timeout',\n",
       " 'uploads',\n",
       " 'user_agent',\n",
       " 'with_options',\n",
       " 'with_raw_response',\n",
       " 'with_streaming_response']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This does automatic tracing with Langfuse\n",
    "from langfuse.openai import AsyncOpenAI\n",
    "\n",
    "client = AsyncOpenAI()\n",
    "GPT_4O_MINI = \"gpt-4o-mini\"\n",
    "\n",
    "dir(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on AsyncOpenAI in module openai object:\n",
      "\n",
      "class AsyncOpenAI(openai._base_client.AsyncAPIClient)\n",
      " |  AsyncOpenAI(*, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'Union[float, Timeout, None, NotGiven]' = NOT_GIVEN, max_retries: 'int' = 2, default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, http_client: 'httpx.AsyncClient | None' = None, _strict_response_validation: 'bool' = False) -> 'None'\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      AsyncOpenAI\n",
      " |      openai._base_client.AsyncAPIClient\n",
      " |      openai._base_client.BaseClient\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'Union[float, Timeout, None, NotGiven]' = NOT_GIVEN, max_retries: 'int' = 2, default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, http_client: 'httpx.AsyncClient | None' = None, _strict_response_validation: 'bool' = False) -> 'None' from openai._client.AsyncOpenAI\n",
      " |      Construct a new async openai client instance.\n",
      " |\n",
      " |      This automatically infers the following arguments from their corresponding environment variables if they are not provided:\n",
      " |      - `api_key` from `OPENAI_API_KEY`\n",
      " |      - `organization` from `OPENAI_ORG_ID`\n",
      " |      - `project` from `OPENAI_PROJECT_ID`\n",
      " |\n",
      " |  copy(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'float | Timeout | None | NotGiven' = NOT_GIVEN, http_client: 'httpx.AsyncClient | None' = None, max_retries: 'int | NotGiven' = NOT_GIVEN, default_headers: 'Mapping[str, str] | None' = None, set_default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, set_default_query: 'Mapping[str, object] | None' = None, _extra_kwargs: 'Mapping[str, Any]' = {}) -> 'Self' from openai._client.AsyncOpenAI\n",
      " |      Create a new client instance re-using the same options given to the current client with optional overriding.\n",
      " |\n",
      " |  with_options = copy(self, *, api_key: 'str | None' = None, organization: 'str | None' = None, project: 'str | None' = None, base_url: 'str | httpx.URL | None' = None, timeout: 'float | Timeout | None | NotGiven' = NOT_GIVEN, http_client: 'httpx.AsyncClient | None' = None, max_retries: 'int | NotGiven' = NOT_GIVEN, default_headers: 'Mapping[str, str] | None' = None, set_default_headers: 'Mapping[str, str] | None' = None, default_query: 'Mapping[str, object] | None' = None, set_default_query: 'Mapping[str, object] | None' = None, _extra_kwargs: 'Mapping[str, Any]' = {}) -> 'Self'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |\n",
      " |  auth_headers\n",
      " |\n",
      " |  default_headers\n",
      " |\n",
      " |  qs\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  __annotations__ = {'api_key': 'str', 'audio': 'resources.AsyncAudio', ...\n",
      " |\n",
      " |  __parameters__ = ()\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._base_client.AsyncAPIClient:\n",
      " |\n",
      " |  async __aenter__(self: '_T') -> '_T'\n",
      " |\n",
      " |  async __aexit__(self, exc_type: 'type[BaseException] | None', exc: 'BaseException | None', exc_tb: 'TracebackType | None') -> 'None'\n",
      " |\n",
      " |  async close(self) -> 'None'\n",
      " |      Close the underlying HTTPX client.\n",
      " |\n",
      " |      The client will *not* be usable after this.\n",
      " |\n",
      " |  async delete(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  async get(self, path: 'str', *, cast_to: 'Type[ResponseT]', options: 'RequestOptions' = {}, stream: 'bool' = False, stream_cls: 'type[_AsyncStreamT] | None' = None) -> 'ResponseT | _AsyncStreamT'\n",
      " |\n",
      " |  get_api_list(self, path: 'str', *, model: 'Type[_T]', page: 'Type[AsyncPageT]', body: 'Body | None' = None, options: 'RequestOptions' = {}, method: 'str' = 'get') -> 'AsyncPaginator[_T, AsyncPageT]'\n",
      " |\n",
      " |  is_closed(self) -> 'bool'\n",
      " |\n",
      " |  async patch(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  async post(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, files: 'RequestFiles | None' = None, options: 'RequestOptions' = {}, stream: 'bool' = False, stream_cls: 'type[_AsyncStreamT] | None' = None) -> 'ResponseT | _AsyncStreamT'\n",
      " |\n",
      " |  async put(self, path: 'str', *, cast_to: 'Type[ResponseT]', body: 'Body | None' = None, files: 'RequestFiles | None' = None, options: 'RequestOptions' = {}) -> 'ResponseT'\n",
      " |\n",
      " |  async request(self, cast_to: 'Type[ResponseT]', options: 'FinalRequestOptions', *, stream: 'bool' = False, stream_cls: 'type[_AsyncStreamT] | None' = None, remaining_retries: 'Optional[int]' = None) -> 'ResponseT | _AsyncStreamT'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from openai._base_client.AsyncAPIClient:\n",
      " |\n",
      " |  __orig_bases__ = (openai._base_client.BaseClient[httpx.AsyncClient, op...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  platform_headers(self) -> 'Dict[str, str]'\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  custom_auth\n",
      " |\n",
      " |  default_query\n",
      " |\n",
      " |  user_agent\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openai._base_client.BaseClient:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      " |\n",
      " |  base_url\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |\n",
      " |  __class_getitem__(...)\n",
      " |      Parameterizes a generic class.\n",
      " |\n",
      " |      At least, parameterizing a generic class is the *main* thing this\n",
      " |      method does. For example, for some generic class `Foo`, this is called\n",
      " |      when we do `Foo[int]` - there, with `cls=Foo` and `params=int`.\n",
      " |\n",
      " |      However, note that this method is also called when defining generic\n",
      " |      classes in the first place with `class Foo[T]: ...`.\n",
      " |\n",
      " |  __init_subclass__(...)\n",
      " |      Function to initialize subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _msg(role: str, content: str) -> dict[str, str]:\n",
    "    return {\"role\": role, \"content\": content}\n",
    "\n",
    "\n",
    "def _system(content: str) -> dict[str, str]:\n",
    "    return _msg(role=\"system\", content=content)\n",
    "\n",
    "\n",
    "def _user(content: str) -> dict[str, str]:\n",
    "    return _msg(role=\"user\", content=content)\n",
    "\n",
    "\n",
    "def _assistant(content: str) -> dict[str, str]:\n",
    "    return _msg(role=\"assistant\", content=content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    await client.chat.completions.create(\n",
    "        messages=[_user(content=\"Hello! I'm Subrata Mondal\")],\n",
    "        model=GPT_4O_MINI,\n",
    "        max_tokens=10,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai-zqkb-BGY-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
